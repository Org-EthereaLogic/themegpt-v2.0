# Agents - OpenAI Agents SDK

## Overview

Agents represent the fundamental component of applications built with this framework. An agent combines a large language model (LLM) with configured instructions and tools.

## Basic Configuration

Key agent properties include:

- **name**: Required identifier string
- **instructions**: System prompt/developer message
- **model**: LLM selection with optional `model_settings` for tuning parameters (temperature, top_p, etc.)
- **tools**: Available functions the agent can invoke

```python
from agents import Agent, ModelSettings, function_tool

@function_tool
def get_weather(city: str) -> str:
    """returns weather info for the specified city."""
    return f"The weather in {city} is sunny"

agent = Agent(
    name="Haiku agent",
    instructions="Always respond in haiku form",
    model="gpt-5-nano",
    tools=[get_weather],
)
```

## Context

Agents support generic context typing for dependency injection. The context object passes through to agents, tools, and handoffs, functioning as a repository for dependencies and state.

```python
@dataclass
class UserContext:
    name: str
    uid: str
    is_pro_user: bool

    async def fetch_purchases() -> list[Purchase]:
        return ...

agent = Agent[UserContext](
    ...,
)
```

## Output Types

By default, agents produce plain text strings. The `output_type` parameter enables structured outputs using Pydantic models, dataclasses, TypedDict, or similar types.

```python
from pydantic import BaseModel
from agents import Agent

class CalendarEvent(BaseModel):
    name: str
    date: str
    participants: list[str]

agent = Agent(
    name="Calendar extractor",
    instructions="Extract calendar events from text",
    output_type=CalendarEvent,
)
```

> Structured outputs use "structured outputs" instead of plain text responses.

## Multi-Agent System Design Patterns

### Manager Pattern (Agents as Tools)

A central manager agent orchestrates specialized sub-agents exposed as tools while maintaining conversation control.

```python
from agents import Agent

booking_agent = Agent(...)
refund_agent = Agent(...)

customer_facing_agent = Agent(
    name="Customer-facing agent",
    instructions=(
        "Handle all direct user communication. "
        "Call the relevant tools when specialized expertise is needed."
    ),
    tools=[
        booking_agent.as_tool(
            tool_name="booking_expert",
            tool_description="Handles booking questions and requests.",
        ),
        refund_agent.as_tool(
            tool_name="refund_expert",
            tool_description="Handles refund questions and requests.",
        )
    ],
)
```

### Handoffs Pattern

Handoffs enable agents to delegate to specialized peers. The delegated agent receives conversation history and assumes control.

```python
from agents import Agent

booking_agent = Agent(...)
refund_agent = Agent(...)

triage_agent = Agent(
    name="Triage agent",
    instructions=(
        "Help the user with their questions. "
        "If they ask about booking, hand off to the booking agent. "
        "If they ask about refunds, hand off to the refund agent."
    ),
    handoffs=[booking_agent, refund_agent],
)
```

## Dynamic Instructions

Instructions can be provided statically or generated dynamically through functions receiving agent and context parameters. Both synchronous and asynchronous functions are supported.

```python
def dynamic_instructions(
    context: RunContextWrapper[UserContext], agent: Agent[UserContext]
) -> str:
    return f"The user's name is {context.context.name}. Help them with their questions."

agent = Agent[UserContext](
    name="Triage agent",
    instructions=dynamic_instructions,
)
```

## Lifecycle Events (Hooks)

Observe agent lifecycle stages by subclassing `AgentHooks` and overriding relevant methods for logging or data pre-fetching.

## Guardrails

Guardrails perform parallel validations on user input and agent output. They enable screening for relevance or other criteria.

## Cloning/Copying Agents

The `clone()` method duplicates an agent while optionally modifying properties.

```python
pirate_agent = Agent(
    name="Pirate",
    instructions="Write like a pirate",
    model="gpt-4.1",
)

robot_agent = pirate_agent.clone(
    name="Robot",
    instructions="Write like a robot",
)
```

## Forcing Tool Use

The `ModelSettings.tool_choice` parameter controls tool invocation:

- **auto**: LLM decides whether to use tools
- **required**: LLM must use a tool
- **none**: LLM cannot use tools
- **specific tool name**: Forces use of that tool

```python
from agents import Agent, Runner, function_tool, ModelSettings

@function_tool
def get_weather(city: str) -> str:
    """Returns weather info for the specified city."""
    return f"The weather in {city} is sunny"

agent = Agent(
    name="Weather Agent",
    instructions="Retrieve weather details.",
    tools=[get_weather],
    model_settings=ModelSettings(tool_choice="get_weather")
)
```

> The framework automatically resets `tool_choice` to "auto" after tool execution to prevent infinite loops.

## Tool Use Behavior

The `tool_use_behavior` parameter manages tool output handling:

### Run LLM Again (Default)

Tools execute and the LLM processes results for final response generation.

### Stop on First Tool

The first tool's output becomes the final response without further processing.

```python
from agents import Agent, Runner, function_tool, ModelSettings

@function_tool
def get_weather(city: str) -> str:
    """Returns weather info for the specified city."""
    return f"The weather in {city} is sunny"

agent = Agent(
    name="Weather Agent",
    instructions="Retrieve weather details.",
    tools=[get_weather],
    tool_use_behavior="stop_on_first_tool"
)
```

### Stop at Specific Tools

Halts execution when specified tools are called, using their output as final response.

```python
from agents import Agent, Runner, function_tool
from agents.agent import StopAtTools

@function_tool
def get_weather(city: str) -> str:
    """Returns weather info for the specified city."""
    return f"The weather in {city} is sunny"

@function_tool
def sum_numbers(a: int, b: int) -> int:
    """Adds two numbers."""
    return a + b

agent = Agent(
    name="Stop At Stock Agent",
    instructions="Get weather or sum numbers.",
    tools=[get_weather, sum_numbers],
    tool_use_behavior=StopAtTools(stop_at_tool_names=["get_weather"])
)
```

### Custom Tool Handler

Implement custom logic via `ToolsToFinalOutputFunction` to process results and determine continuation.

```python
from agents import Agent, Runner, function_tool, FunctionToolResult, RunContextWrapper
from agents.agent import ToolsToFinalOutputResult
from typing import List, Any

@function_tool
def get_weather(city: str) -> str:
    """Returns weather info for the specified city."""
    return f"The weather in {city} is sunny"

def custom_tool_handler(
    context: RunContextWrapper[Any],
    tool_results: List[FunctionToolResult]
) -> ToolsToFinalOutputResult:
    """Processes tool results to decide final output."""
    for result in tool_results:
        if result.output and "sunny" in result.output:
            return ToolsToFinalOutputResult(
                is_final_output=True,
                final_output=f"Final weather: {result.output}"
            )
    return ToolsToFinalOutputResult(
        is_final_output=False,
        final_output=None
    )

agent = Agent(
    name="Weather Agent",
    instructions="Retrieve weather details.",
    tools=[get_weather],
    tool_use_behavior=custom_tool_handler
)
```
